<!DOCTYPE html>

<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
  
  <title>《Kafka环境配置》 [ Hexo ]</title>
  
    <!-- stylesheets list from config.yml -->
    
      <link rel="stylesheet" href="/css/iLiKE.css">
    
  
  
  
  <script src="//cdn1.lncld.net/static/js/3.1.1/av-min.js"></script>
    <script id="leancloud">
      AV.init({
          appId: "6E5zTbTljdUbVW2WkXPsXGJk-gzGzoHsz",
          appKey: "0vsyDKfNpeSECAI70J794ugv"
      });
    </script>

<meta name="generator" content="Hexo 6.2.0"></head>
<body>
    <div class="header">
        <div class="container">
    <div class="menu">
      <div class="menu-left">
        <a href="/">
          <img src="/favicon.ico"></img>
        </a>
      </div>
      <div class="menu-right">
        
          
          
          
          
          
          
          <a href="/">Home</a>
        
          
          
          
          
          
          
          <a href="/archives">Archives</a>
        
          
          
          
          
          
          
          <a href="/about">About</a>
        
      </div>
    </div>
</div>
    </div>
    <div class="container">
        <h1 class="post-title">《Kafka环境配置》</h1>
<article class="post markdown-style">
  <h1 id="《Kafka环境配置》"><a href="#《Kafka环境配置》" class="headerlink" title="《Kafka环境配置》"></a>《Kafka环境配置》</h1><hr>
<p>title: 《Kafka环境配置》<br>date: 2022-6-7 21:20:41<br>description: Spark (HA) Spark (Yarn)</p>
<details>
<summary>阅读全文</summary>

<p>**<summary><br>kafka 安装配置<br>Kafka是一种高吞吐量的分布式发布订阅消息系统，其在大数据开发应用上的目的是通过 Hadoo的并行加载机制来统一线上和离线的消息处理，也是为了通过集群来提供实时的消息。大数据开发需掌握Kafka架构原理及各组件的作用和使用方法及相关功能的实现。</p>
<p>上传文件包 到&#x2F;export&#x2F;server&#x2F;<br>解压文件</p>
<blockquote>
<blockquote>
<blockquote>
</blockquote>
<pre><code>tar -zxvf kafka_2.11-2.0.0.tgz
</code></pre>
</blockquote>
</blockquote>
<p>创建软连接</p>
<blockquote>
<blockquote>
<blockquote>
</blockquote>
<pre><code>ln -s kafka_2.11-2.0.0/ kafka
</code></pre>
</blockquote>
</blockquote>
<p>进入 &#x2F;export&#x2F;server&#x2F;kafka&#x2F;config 修改 配置文件 server.properties</p>
<blockquote>
<blockquote>
<blockquote>
</blockquote>
<p>   cd &#x2F;export&#x2F;server&#x2F;kafka&#x2F;config vim server.properties</p>
</blockquote>
</blockquote>
<p>(1)21 行内容 broker.id&#x3D;0 为依次增长的:0、1、2、3、4,集群中唯一 id 从0开始，每台不能重复<br>（注：此处不用修改）</p>
<blockquote>
<blockquote>
<blockquote>
</blockquote>
<p>   21 broker.id&#x3D;0</p>
</blockquote>
</blockquote>
<p>(2)31 行内容 #listeners&#x3D;PLAINTEXT:&#x2F;&#x2F;:9092 取消注释，内容改为：<br>listeners&#x3D;PLAINTEXT:&#x2F;&#x2F;master:9092<br>PLAINTEXT为通信使用明文（加密ssl）</p>
<blockquote>
<blockquote>
<blockquote>
</blockquote>
<p>   31 listeners&#x3D;PLAINTEXT:&#x2F;&#x2F;master:9092</p>
</blockquote>
</blockquote>
<p>(3)59 行内容 log.dirs&#x3D;&#x2F;tmp&#x2F;kafka-logs 为默认日志文件存储的位置，改为<br>log.dirs&#x3D;&#x2F;export&#x2F;server&#x2F;data&#x2F;kafka-logs</p>
<blockquote>
<blockquote>
<blockquote>
</blockquote>
<p>   59 log.dirs&#x3D;&#x2F;export&#x2F;data&#x2F;kafka-logs</p>
</blockquote>
</blockquote>
<p>(4)63 行内容为 num.partitions&#x3D;1 是默认分区数</p>
<blockquote>
<blockquote>
<blockquote>
</blockquote>
<pre><code>63 num.partitions=1
</code></pre>
</blockquote>
</blockquote>
<p>(5)76 行部分</p>
<blockquote>
<blockquote>
<blockquote>
<p>  ############################ <strong>Log Flush Policy</strong> ############################### </p>
</blockquote>
</blockquote>
</blockquote>
<p>数据安全性（持久化之前先放到缓存上，从缓存刷到磁盘上）interval.messages interval.ms</p>
<p>(6)93 行部分</p>
<blockquote>
<blockquote>
<blockquote>
</blockquote>
<pre><code>########################### **Log Retention Policy**############################ 
</code></pre>
</blockquote>
</blockquote>
<pre><code>数据保留策略 168/24=7，1073741824/1024=1GB，300000ms = 300s = 5min超过了删掉 （最后修改时间还是创建时间--&gt;日志段中最晚的一条消息，维护这个最大的时间戳--&gt;用户无法 干预
</code></pre>
<p>(7)121 行内容 zookeeper.connect&#x3D;localhost:2181 修改为zookeeper.connect&#x3D;master:2181,slave1:2181,slave2:2181</p>
<blockquote>
<blockquote>
<blockquote>
</blockquote>
<p>   121 zookeeper.connect&#x3D;master:2181,slave1:2181,slave2:2181</p>
</blockquote>
</blockquote>
<p>(8)126 行内容 group.initial.rebalance.delay.ms&#x3D;0 修改为group.initial.rebalance.delay.ms&#x3D;3000</p>
<blockquote>
<blockquote>
<blockquote>
</blockquote>
<p>   133 group.initial.rebalance.delay.ms&#x3D;3000</p>
</blockquote>
</blockquote>
<p>(9)给 slaves1和 slavs2 scp 分发 kafka<br>cd &#x2F;export&#x2F;server&#x2F; </p>
<blockquote>
<blockquote>
<blockquote>
</blockquote>
<p>   scp -r &#x2F;export&#x2F;server&#x2F;kafka_2.11-2.0.0&#x2F; slave1:$PWD<br>   scp -r &#x2F;export&#x2F;server&#x2F;kafka_2.11-2.0.0&#x2F; slave2:$PWD</p>
</blockquote>
</blockquote>
<p>(10)创建软连接</p>
<blockquote>
<blockquote>
<blockquote>
<p>   ln -s &#x2F;export&#x2F;server&#x2F;kafka_2.11-2.0.0&#x2F; kafka</p>
</blockquote>
</blockquote>
</blockquote>
<p>(11)配置 kafka 环境变量（注：可以一台一台配，也可以在 master 完成后发给 slave1 和slave2）</p>
<blockquote>
<blockquote>
<blockquote>
</blockquote>
<p>   vim &#x2F;etc&#x2F;profile # kafka 环境变量 export KAFKA_HOME&#x3D;&#x2F;export&#x2F;server&#x2F;kafka export PATH&#x3D;$PATH:$KAFKA_HOME&#x2F;bin</p>
</blockquote>
</blockquote>
<p>(12)重新加载环境变量</p>
<blockquote>
<blockquote>
<blockquote>
</blockquote>
<p>   source &#x2F;etc&#x2F;profile</p>
</blockquote>
</blockquote>
<p>(13)分别在 slave1 和slave2 上修改配置文件 路径：&#x2F;export&#x2F;server&#x2F;kafka&#x2F;config<br>将文件 server.properties 的第 21 行的 broker.id&#x3D;0 修改为 broker.id&#x3D;1 同理 slave2 同样操<br>作</p>
<blockquote>
<blockquote>
<blockquote>
</blockquote>
<p>   21 broker.id&#x3D;1</p>
</blockquote>
</blockquote>
<p>(14)将文件 server.properties 的第 31 行的 listeners&#x3D;PLAINTEXT:&#x2F;&#x2F;master:9092 修改为<br>listeners&#x3D;PLAINTEXT:&#x2F;&#x2F;slave1:9092 同理slave2 同样操作</p>
<blockquote>
<blockquote>
<blockquote>
</blockquote>
<p>   31 listeners&#x3D;PLAINTEXT:&#x2F;&#x2F;slave1:9092</p>
</blockquote>
</blockquote>
<p>(15)启停 kafka (注：kafka 启动需要在 zookeeper 启动的情况下才可)</p>
<blockquote>
<blockquote>
<blockquote>
</blockquote>
<p>   kafka-server-start.sh -daemon &#x2F;export&#x2F;server&#x2F;kafka&#x2F;config&#x2F;server.properties</p>
</blockquote>
</blockquote>
<p>   hadoop，zookeeper，kafka启动<br>   结果显示： </p>
<blockquote>
<blockquote>
<blockquote>
</blockquote>
<p>   (base) [root@master ~]# jps<br>   11793 NodeManager<br>   91699 Kafka<br>   85618 QuorumPeerMain<br>   10697 NameNode<br>   10924 DataNode<br>   11596ResourceManager<br>   109852 Jps </p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
</blockquote>
<p>   [root@slave1 ~]# jps<br>   9301 DataNode<br>   9493 SecondaryNameNode<br>   95959 Kafka<br>   102971 Jps<br>   9855 NodeManager<br>   89534 QuorumPeerMain </p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
</blockquote>
<p>   [root@slave2 ~]# jps<br>   88660 QuorumPeerMain<br>   95204 Kafka<br>   9110 NodeManager<br>   8616 DataNode<br>   102104 Jps</p>
</blockquote>
</blockquote>
<p>   关闭 kafka<br>   kafka-server-stop.sh stop</p>
<p>定制脚本一键启动</p>
<blockquote>
<blockquote>
<blockquote>
</blockquote>
<p>   vim kafka-all.sh<br>   放入 &#x2F;bin 路径下</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<blockquote>
</blockquote>
<p>   #!&#x2F;bin&#x2F;bash<br>   if [ $# -eq 0 ] ;<br>   then<br>       echo “please input param:start stop”<br>   else<br>   if [ $1 &#x3D; start ] ;then<br>       echo “${1}ing master”<br>       ssh master “source &#x2F;etc&#x2F;profile;kafka-server-start.sh -daemon &#x2F;export&#x2F;server&#x2F;kafka&#x2F;config&#x2F;server.properties”<br>       for i in {1..2}<br>       do<br>          echo “${1}ing slave${i}”<br>          ssh slave${i} “source &#x2F;etc&#x2F;profile;kafka-server-start.sh -daemon &#x2F;export&#x2F;server&#x2F;kafka&#x2F;config&#x2F;server.properties”<br>      done<br>   fi<br>   if [ $1 &#x3D; stop ];then<br>       echo “${1}ping master “<br>       ssh master “source &#x2F;etc&#x2F;profile;kafka-server-stop.sh”<br>      for i in {1..2}<br>      do<br>         echo “${1}ping slave${i}”<br>         ssh slave${i} “source &#x2F;etc&#x2F;profile;kafka-server-stop.sh”<br>      done<br>   fi<br>   fi<br>**</p>
</blockquote>
</blockquote>
</details>

<hr>

</article>

    <div class="pagenator post-pagenator">
    
    
        <a class="extend prev post-prev" href="/2022/06/09/gx/">prev</a>
    

    
    <p>last update time 2022-06-07</p>
    
    
        <a class="extend next post-next" href="/2022/06/07/2/">next</a>
    
    </div>


    </div>
    <div class="footer">
        <div class="container">
    <div class="social">
	<ul class="social-list">
		
			
				
				
				<li>
					<a href="mailto:1178752402@qq.com" title="email" target="_blank">
					<i class="fa fa-email"></i>
					</a>
				</li>
			
		
			
		
			
		
			
		
			
		
			
		
			
				
				<li>
					<a href="https://github.com/CaiChenghan" title="github" target="_self">
					<i class="fa fa-github"></i>
					</a>
				</li>
			
		
			
		
			
		
			
		
			
				
				<li>
					<a href="https://www.jianshu.com/u/565c8e790605" title="jianshu" target="_self">
					<i class="fa fa-jianshu"></i>
					</a>
				</li>
			
		
			
		
			
		
			
		
	</ul>
</div>
    <div class="copyright">
        <span>
            
            
            
                © John Doe 2017 - 2022
            
        </span>
    </div>
    <div class="power">
        <span>
            Powered by <a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a> & <a target="_blank" rel="noopener" href="https://github.com/CaiChenghan/iLiKE">iLiKE Theme</a>
        </span>
    </div>
    <script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.js"></script>
    <!--page counter part-->
<script>
function addCount (Counter) {
    url=$('.article-date').attr('href').trim();
    title = $('.article-title').text().trim();
    var query = new AV.Query(Counter);
    //use url as unique idnetfication
    query.equalTo("url",url);
    query.find({
        success: function(results) {
            if (results.length>0) {
                var counter=results[0];
                counter.fetchWhenSave(true); //get recent result
                counter.increment("time");
                counter.save();
            } else {
                var newcounter=new Counter();
                newcounter.set("title",title);
                newcounter.set("url",url);
                newcounter.set("time",1);
                newcounter.save(null,{
                    success: function(newcounter) {
                        //alert('New object created');
                    }, error: function(newcounter,error) {
                        alert('Failed to create');
                    }
                })
            }
        },
        error: function(error) {
            //find null is not a error
            alert('Error:'+error.code+" "+error.message);
        }
    });
}
$(function() {
    var Counter=AV.Object.extend("Counter");
    //only increse visit counting when intering a page
    if ($('.article-title').length == 1) {
       addCount(Counter);
    }
    var query=new AV.Query(Counter);
    query.descending("time");
    // the sum of popular posts
    query.limit(10); 
    query.find({
        success: function(results) {
                for(var i=0;i<results.length;i++) {
                    var counter=results[i];
                    title=counter.get("title");
                    url=counter.get("url");
                    time=counter.get("time");
                    // add to the popularlist widget
                    showcontent=title+" ("+time+")";
                    //notice the "" in href
                    $('.popularlist').append('<li><a href="'+url+'">'+showcontent+'</a></li>');
                }
            },
        error: function(error) {
            alert("Error:"+error.code+" "+error.message);
        }
    });
});
</script>
</div>
    </div>
</body>
</html>
