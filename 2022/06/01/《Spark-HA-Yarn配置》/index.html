<!DOCTYPE html>

<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
  
  <title>《Spark HA &amp; Yarn配置》 [ Hexo ]</title>
  
    <!-- stylesheets list from config.yml -->
    
      <link rel="stylesheet" href="/css/iLiKE.css">
    
  
  
  
  <script src="//cdn1.lncld.net/static/js/3.1.1/av-min.js"></script>
    <script id="leancloud">
      AV.init({
          appId: "6E5zTbTljdUbVW2WkXPsXGJk-gzGzoHsz",
          appKey: "0vsyDKfNpeSECAI70J794ugv"
      });
    </script>

<meta name="generator" content="Hexo 6.2.0"></head>
<body>
    <div class="header">
        <div class="container">
    <div class="menu">
      <div class="menu-left">
        <a href="/">
          <img src="/favicon.ico"></img>
        </a>
      </div>
      <div class="menu-right">
        
          
          
          
          
          
          
          <a href="/">Home</a>
        
          
          
          
          
          
          
          <a href="/archives">Archives</a>
        
          
          
          
          
          
          
          <a href="/about">About</a>
        
      </div>
    </div>
</div>
    </div>
    <div class="container">
        <h1 class="post-title">《Spark HA &amp; Yarn配置》</h1>
<article class="post markdown-style">
  <h1 id="七、spark-standalone-HA环境搭建（需要更新zookeeper版本，略）"><a href="#七、spark-standalone-HA环境搭建（需要更新zookeeper版本，略）" class="headerlink" title="七、spark standalone HA环境搭建（需要更新zookeeper版本，略）"></a>七、spark standalone HA环境搭建（需要更新zookeeper版本，略）</h1><p>前提: 确保Zookeeper 和 HDFS 均已经启动</p>
<p>先在<code>spark-env.sh</code>中, <strong>删除</strong>: <code>SPARK_MASTER_HOST=node1</code></p>
<p>原因: 配置文件中固定master是谁, 那么就无法用到zk的动态切换master功能了.</p>
<p>在<code>spark-env.sh</code>中, 增加:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">SPARK_DAEMON_JAVA_OPTS=&quot;-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=node1:2181,node2:2181,node3:2181 -Dspark.deploy.zookeeper.dir=/spark-ha&quot;</span><br><span class="line"></span><br><span class="line">\# spark.deploy.recoveryMode 指定HA模式 基于Zookeeper实现</span><br><span class="line"></span><br><span class="line">\# 指定Zookeeper的连接地址</span><br><span class="line"></span><br><span class="line">\# 指定在Zookeeper中注册临时节点的路径</span><br></pre></td></tr></table></figure>

<p>将spark-env.sh 分发到每一台服务器上</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scp spark-env.sh node2:/export/server/spark/conf/</span><br><span class="line"></span><br><span class="line">scp spark-env.sh node3:/export/server/spark/conf/</span><br></pre></td></tr></table></figure>

<p>停止当前StandAlone集群</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/stop-all.sh</span><br></pre></td></tr></table></figure>

<p>启动集群:</p>
<p># 在node1上 启动一个master 和全部worker</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/start-all.sh</span><br></pre></td></tr></table></figure>

<p># 注意, 下面命令在node2上执行</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/start-master.sh</span><br></pre></td></tr></table></figure>

<p># 在node2上启动一个备用的master进程</p>
<p>status：standby node2备用master状态是standby</p>
<p>master主备切换</p>
<p>提交一个spark任务到当前<code>alive</code>master上:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-submit --master spark://node1:7077 /export/server/spark/examples/src/main/python/pi.py 1000</span><br></pre></td></tr></table></figure>

<p>在提交成功后, 将alivemaster直接kill掉</p>
<p>不会影响程序运行:</p>
<p>结论 HA模式下, 主备切换 不会影响到正在运行的程序.</p>
<p>最大的影响是 会让它中断大约30秒左右.</p>
<h1 id="八、Spark-On-YARN-环境搭建"><a href="#八、Spark-On-YARN-环境搭建" class="headerlink" title="八、Spark On YARN 环境搭建"></a>八、Spark On YARN 环境搭建</h1><p>前提：在spark-env.sh  以及 环境变量配置文件- HADOOP_CONF_DIR</p>
<p>- YARN_CONF_DIR</p>
<h2 id="1-启动yarn集群历史服务器"><a href="#1-启动yarn集群历史服务器" class="headerlink" title="1.启动yarn集群历史服务器"></a>1.启动yarn集群历史服务器</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /export/server/hadoop/sbin/</span><br><span class="line"></span><br><span class="line">./mr-jobhistory-daemon.sh start historyserver</span><br></pre></td></tr></table></figure>
<h2 id="2-在yarn上启动pyspark"><a href="#2-在yarn上启动pyspark" class="headerlink" title="2.在yarn上启动pyspark"></a>2.在yarn上启动pyspark</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /export/server/hadoop/etc/hadoop</span><br><span class="line"></span><br><span class="line">/export/server/spark/bin/pyspark --master yarn</span><br></pre></td></tr></table></figure>


<p>执行测试命令 sc.parallelize([1,2,3,4,5]).map(lambda x: x*10).collect()</p>
<p>&#x2F;export&#x2F;server&#x2F;spark目录下执行</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-submit --master yarn /export/server/spark/examples/src/main/python/pi.py 10</span><br></pre></td></tr></table></figure>
<h2 id="3-验证client模式"><a href="#3-验证client模式" class="headerlink" title="3.验证client模式"></a>3.验证client模式</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">/export/server/spark/bin/spark-submit --master yarn --deploy-mode client --driver-memory 512m --executor-memory 512m --num-executors 3 --total-executor-cores 3 /export/server/spark/examples/src/main/python/pi.py 3</span><br><span class="line">``</span><br><span class="line">## 4.验证cluster模式</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>&#x2F;export&#x2F;server&#x2F;spark&#x2F;bin&#x2F;spark-submit –master yarn –deploy-mode cluster –driver-memory 512m –executor-memory 512m –num-executors 3 –total-executor-cores 3 &#x2F;export&#x2F;server&#x2F;spark&#x2F;examples&#x2F;src&#x2F;main&#x2F;python&#x2F;pi.py 3</p>
<p>&#96;&#96;&#96;</p>
<p>至此基础环境-&gt;JDK-&gt;Hadoop-&gt;Zookeeper-&gt;Spark(local)-&gt;Spark(stand-alone) -&gt;Spark(HA)-&gt;Spark(Yarn)已全部配置完成。</p>

</article>

    <div class="pagenator post-pagenator">
    
    
        <a class="extend prev post-prev" href="/2022/06/05/Eagle%E3%80%8B/">prev</a>
    

    
    <p>last update time 2022-06-01</p>
    
    
        <a class="extend next post-next" href="/2022/06/01/%E3%80%8ASpark-local-stand-alone%E9%85%8D%E7%BD%AE%E3%80%8B/">next</a>
    
    </div>


    </div>
    <div class="footer">
        <div class="container">
    <div class="social">
	<ul class="social-list">
		
			
				
				
				<li>
					<a href="mailto:1178752402@qq.com" title="email" target="_blank">
					<i class="fa fa-email"></i>
					</a>
				</li>
			
		
			
		
			
		
			
		
			
		
			
		
			
				
				<li>
					<a href="https://github.com/CaiChenghan" title="github" target="_self">
					<i class="fa fa-github"></i>
					</a>
				</li>
			
		
			
		
			
		
			
		
			
				
				<li>
					<a href="https://www.jianshu.com/u/565c8e790605" title="jianshu" target="_self">
					<i class="fa fa-jianshu"></i>
					</a>
				</li>
			
		
			
		
			
		
			
		
	</ul>
</div>
    <div class="copyright">
        <span>
            
            
            
                © John Doe 2017 - 2022
            
        </span>
    </div>
    <div class="power">
        <span>
            Powered by <a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a> & <a target="_blank" rel="noopener" href="https://github.com/CaiChenghan/iLiKE">iLiKE Theme</a>
        </span>
    </div>
    <script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.js"></script>
    <!--page counter part-->
<script>
function addCount (Counter) {
    url=$('.article-date').attr('href').trim();
    title = $('.article-title').text().trim();
    var query = new AV.Query(Counter);
    //use url as unique idnetfication
    query.equalTo("url",url);
    query.find({
        success: function(results) {
            if (results.length>0) {
                var counter=results[0];
                counter.fetchWhenSave(true); //get recent result
                counter.increment("time");
                counter.save();
            } else {
                var newcounter=new Counter();
                newcounter.set("title",title);
                newcounter.set("url",url);
                newcounter.set("time",1);
                newcounter.save(null,{
                    success: function(newcounter) {
                        //alert('New object created');
                    }, error: function(newcounter,error) {
                        alert('Failed to create');
                    }
                })
            }
        },
        error: function(error) {
            //find null is not a error
            alert('Error:'+error.code+" "+error.message);
        }
    });
}
$(function() {
    var Counter=AV.Object.extend("Counter");
    //only increse visit counting when intering a page
    if ($('.article-title').length == 1) {
       addCount(Counter);
    }
    var query=new AV.Query(Counter);
    query.descending("time");
    // the sum of popular posts
    query.limit(10); 
    query.find({
        success: function(results) {
                for(var i=0;i<results.length;i++) {
                    var counter=results[i];
                    title=counter.get("title");
                    url=counter.get("url");
                    time=counter.get("time");
                    // add to the popularlist widget
                    showcontent=title+" ("+time+")";
                    //notice the "" in href
                    $('.popularlist').append('<li><a href="'+url+'">'+showcontent+'</a></li>');
                }
            },
        error: function(error) {
            alert("Error:"+error.code+" "+error.message);
        }
    });
});
</script>
</div>
    </div>
</body>
</html>
